{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88133b1a-61ca-4e97-9bf5-ddb856349c60",
   "metadata": {},
   "source": [
    "# 測試甚麼?\n",
    "1. 把所有大項目的文字取出,加入一個list,注意不取第一項,因為不符合同一個所需div,但不只定會取到\n",
    "\n",
    "2. 用list.index(\"需要的大項目名稱\"),計算出在list的位置\n",
    "\n",
    "3. 就可以取出你要的大項目裡的資料,使用find[index]\n",
    "\n",
    "4. try excet沒有就取空白"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7741614-969b-4f85-b7ac-5163ec1fae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t成功版本\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "s = Service(\"./chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "driver.get(\"https://www.yes123.com.tw/wk_index/job.asp?p_id=20110211160133_28771443&job_id=20140124095456_13304731\")\n",
    "time.sleep(5)\n",
    "onepage_detail_pagesource = driver.page_source\n",
    "driver.close()\n",
    "\n",
    "div_results=[]\n",
    "soup = BeautifulSoup(str(onepage_detail_pagesource), 'html.parser')\n",
    "test2 = soup.find_all(\"div\",{\"class\":\"job_explain\"})[:-1]\n",
    "for okok in test2:\n",
    "    ok = okok.find(\"h3\").text\n",
    "    print(ok)\n",
    "    div_results.append(ok)\n",
    "#     div_results.append(okok)\n",
    "print(div_results)\n",
    "print(div_results.index(\"工作條件\"))\n",
    "\n",
    "try:\n",
    "    a=div_results.index(\"工作條件\")\n",
    "    test3 = soup.find_all(\"div\",{\"class\":\"job_explain\"})[a].find_all(\"span\",{\"class\":\"right_main\"})[1].text\n",
    "    print(test3)\n",
    "except:\n",
    "    test3=\" \"\n",
    "    print(test3)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9d360-44ac-4792-be83-05259d94528b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#t成功版本\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "s = Service(\"./chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "driver.get(\"https://www.yes123.com.tw/wk_index/job.asp?p_id=20110211160133_28771443&job_id=20140124095456_13304731\")\n",
    "time.sleep(5)\n",
    "onepage_detail_pagesource = driver.page_source\n",
    "driver.close()\n",
    "\n",
    "div_results=[]\n",
    "soup = BeautifulSoup(str(onepage_detail_pagesource), 'html.parser')\n",
    "test2 = soup.find_all(\"div\",{\"class\":\"job_explain\"})[:-1]\n",
    "for okok in test2:\n",
    "    ok = okok.find(\"h3\").text\n",
    "    print(ok)\n",
    "    div_results.append(ok)\n",
    "#     div_results.append(okok)\n",
    "print(div_results)\n",
    "print(div_results.index(\"工作條件\"))\n",
    "\n",
    "try:\n",
    "    a=div_results.index(\"工作條件\")\n",
    "    print(a)\n",
    "    test3 = soup.find_all(\"div\",{\"class\":\"job_explain\"})[a].find_all(\"span\",{\"class\":\"right_main\"})[1].text\n",
    "    print(test3)\n",
    "except:\n",
    "    test3=\" \"\n",
    "    print(test3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffeb8a9-0f4c-4f51-9711-ea6c0d1aa236",
   "metadata": {},
   "source": [
    "# 把所有要取出的內容條件寫出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e0673-3e1a-465d-9ce4-ec038f2336b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 科系要求\n",
    "try:\n",
    "    a=div_results.index(\"工作條件\")\n",
    "    job_dep_div =soup.find_all(\"div\",{\"class\":\"job_explain\"})[a].find_all(\"span\",{\"class\":\"right_main\"})[1].text\n",
    "    print(job_dep_div)\n",
    "except:\n",
    "    job_dep_div=\" \"\n",
    "    print(job_dep_div)\n",
    "\n",
    "print(\"===================================\")\n",
    "# 學歷ok\n",
    "try:\n",
    "    c=div_results.index(\"工作條件\")\n",
    "    job_sch_div = soup.find_all(\"div\",{\"class\":\"job_explain\"})[c].find_all(\"li\")[0].find(\"span\",{\"class\":\"right_main\"}).text    \n",
    "    print(job_sch_div)\n",
    "except:\n",
    "    job_sch_div=\" \"\n",
    "    print(job_sch_div)\n",
    "\n",
    "print(\"===================================\")\n",
    "# 擅長工具ok\n",
    "try:\n",
    "    b=div_results.index(\"技能與求職專長\")\n",
    "    job_can_div = soup.find_all(\"div\",{\"class\":\"job_explain\"})[4].find_all(\"span\",{\"class\":\"right_main\"})\n",
    "    for i in job_can_div:\n",
    "        print(i.get_text())\n",
    "except:\n",
    "    job_can_div=\" \"\n",
    "    print(job_can_div)\n",
    "print(\"===================================\")\n",
    "# 其他條件ok\n",
    "try:\n",
    "    b=div_results.index(\"其他條件\")\n",
    "    job_other_div = soup.find_all(\"div\",{\"class\":\"job_explain\"})[5].find_all(\"span\",{\"class\":\"exception\"})\n",
    "    for i in job_other_div:\n",
    "        print(i.get_text())\n",
    "except:\n",
    "    job_other_div=\" \"\n",
    "    print(job_other_div)\n",
    "print(\"===================================\")\n",
    "#薪資\n",
    "job_salary_div = soup.find(\"div\",{\"class\":\"job_explain mt\"}).find_all(\"span\",{\"class\":\"right_main\"})[1].text\n",
    "print(job_salary_div)\n",
    "print(\"===================================\")\n",
    "#工作內容\n",
    "job_content_div = soup.find(\"div\",{\"class\":\"job_explain mt\"}).find_all(\"span\",{\"class\":\"right_main\"})[0].text\n",
    "print(job_content_div)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a54032f-52be-43b3-9df0-4870881c4895",
   "metadata": {},
   "source": [
    "## 抓一頁裡面的三個職稱詳細內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa850747-f31e-4672-807b-5a620b0ba2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job.asp?p_id=9119793_12868358&job_id=20220307095613_29676330\n",
      "job.asp?p_id=9119793_12868358&job_id=20220425035753_212399\n",
      "job.asp?p_id=20150413153626_22868808&job_id=20150416171817_60838867\n",
      "job.asp?p_id=20100909173802_97176270&job_id=20220803160355_32292466\n",
      "job.asp?p_id=9119793_12868358&job_id=20220411083659_31580750\n",
      "job.asp?p_id=20210916120204_83380293&job_id=20210916133523_42708271\n",
      "job.asp?p_id=20201116113844_53973410&job_id=20211224163219_58501229\n",
      "job.asp?p_id=20201116113844_53973410&job_id=20211224163044_26037192\n",
      "job.asp?p_id=20210309092036_37699350&job_id=20220608002355_31058191\n",
      "job.asp?p_id=20201007095801_64836569&job_id=20210709115944_64555878\n",
      "job.asp?p_id=20210413094522_82878689&job_id=20210413095737_3152205\n",
      "job.asp?p_id=20211014100746_81481154&job_id=20211014101212_8094439\n",
      "job.asp?p_id=20190124181748_24628093&job_id=20220119064557_17034125\n",
      "job.asp?p_id=20220808170732_29164121&job_id=20220808171727_32475525\n",
      "job.asp?p_id=20210714114242_57658906&job_id=20211206162250_49802581\n",
      "job.asp?p_id=20200716093206_85484619&job_id=20210817105556_724835\n",
      "job.asp?p_id=20200623161052_28380348&job_id=20200722161007_17726482\n",
      "job.asp?p_id=20220614102708_83580757&job_id=20220614105253_2994991\n",
      "job.asp?p_id=20220614102708_83580757&job_id=20220614105254_10340472\n",
      "job.asp?p_id=20150806092901_13052368&job_id=20150807155509_10046213\n",
      "job.asp?p_id=3611370_72641237&job_id=20220210135412_7998793\n",
      "job.asp?p_id=20211104170555_65221006&job_id=20211105101010_7857130\n",
      "job.asp?p_id=20220420103727_90431992&job_id=20220421152618_46885499\n",
      "job.asp?p_id=20130430110144_04684390&job_id=20220225105158_58243536\n",
      "job.asp?p_id=3611370_72641237&job_id=20220210123741_21514446\n",
      "job.asp?p_id=20210730181623_82487016&job_id=20210730182625_44948384\n",
      "job.asp?p_id=20210714114242_57658906&job_id=20210723150948_44030223\n",
      "job.asp?p_id=20100823102946_27241615&job_id=20100907110659_29508406\n",
      "job.asp?p_id=20190828113800_36824289&job_id=20220316101953_40280308\n",
      "job.asp?p_id=20210709155842_28592976&job_id=20210709160313_51643037\n",
      "30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m all_detail_page \u001b[38;5;129;01min\u001b[39;00m link_results:\n\u001b[0;32m     36\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(all_detail_page)\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     onepage_detail_pagesource \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mpage_source\n\u001b[0;32m     39\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)    \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "#抓單頁搜尋結果pagesource\n",
    "s = Service(\"./chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "driver.get(\"https://www.yes123.com.tw/wk_index/joblist.asp?find_key2=%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB&order_ascend=desc&strrec=30&search_key_word=%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB&search_from=joblist\")\n",
    "time.sleep(2)\n",
    "job_titlepage = driver.page_source\n",
    "soup = BeautifulSoup(str(job_titlepage), 'html.parser')\n",
    "\n",
    "#取出前四比title的連結\n",
    "job_titlepage_div = soup.find_all(\"div\",{\"class\":\"Job_opening_item_title\"})\n",
    "yes123_host = \"https://www.yes123.com.tw/wk_index/\"\n",
    "link_results =  []\n",
    "\n",
    "for link in job_titlepage_div:\n",
    "    try:\n",
    "        # 連結ˊ\n",
    "        all_part_links = link.find(\"h5\").find(\"a\").get(\"href\")\n",
    "        # print(all_title_links)\n",
    "        print(all_part_links)\n",
    "        all_title_links = yes123_host+all_part_links\n",
    "        # print(all_title_links)\n",
    "        link_results.append(all_title_links)\n",
    "    except:\n",
    "         continue   \n",
    "print(len(link_results))\n",
    "page_source_results=[]\n",
    "for all_detail_page in link_results:\n",
    "    driver.get(all_detail_page)\n",
    "    time.sleep(3)\n",
    "    onepage_detail_pagesource = driver.page_source\n",
    "    time.sleep(1)    \n",
    "    soup2 = BeautifulSoup(str(onepage_detail_pagesource), 'html.parser')\n",
    "    page_source_results.append(soup2) \n",
    "driver.close()\n",
    "print(len(page_source_results))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da341e56-3db8-45f7-9e93-b291d3193685",
   "metadata": {},
   "source": [
    "# 測試 : 詳細頁面的所有資料都可以爬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd048c-b44d-4cb8-af1b-a1594d491618",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for new in page_source_results:\n",
    "    div_results=[]\n",
    "    test2 = new.find_all(\"div\",{\"class\":\"job_explain\"})[1:-1]\n",
    "    \n",
    "    for okok in test2:\n",
    "        ok = okok.find(\"h3\").text\n",
    "        print(type(okok))\n",
    "        div_results.append(ok)\n",
    "    #     div_results.append(okok)\n",
    "    print(div_results)\n",
    "    # print(div_results.index(\"工作條件\"))\n",
    "#     print(\"(學歷,科系要求)=============================================================\")\n",
    "#     try:\n",
    "#         a=div_results.index(\"工作條件\")\n",
    "#         # print(a)\n",
    "#         test4 =  new.find_all(\"div\",{\"class\":\"job_explain\"})[a+1].find_all(\"span\",{\"class\":\"right_main\"})[0].text\n",
    "#         test3 = new.find_all(\"div\",{\"class\":\"job_explain\"})[a+1].find_all(\"span\",{\"class\":\"right_main\"})[1].text\n",
    "#         print(test4)\n",
    "#         print(test3)      \n",
    "#     except:\n",
    "#         test3=\"nono \"\n",
    "#         print(test4)\n",
    "#         print(test3)\n",
    "#     print(\"(薪資)=============================================================\")\n",
    "#     job_salary_div = new.find(\"div\",{\"class\":\"job_explain mt\"}).find_all(\"span\",{\"class\":\"right_main\"})[1].text\n",
    "#     print(job_salary_div)\n",
    "#     print(\"(工作內容)=============================================================\")\n",
    "#     job_content_div = new.find(\"div\",{\"class\":\"job_explain mt\"}).find_all(\"span\",{\"class\":\"right_main\"})[0].text\n",
    "#     print(job_content_div)\n",
    "#     print(\"(擅長)=============================================================\")\n",
    "#     try:\n",
    "#         b=div_results.index(\"技能與求職專長\")\n",
    "#         job_can_div = new.find_all(\"div\",{\"class\":\"job_explain\"})[b+1].find_all(\"span\",{\"class\":\"right_main\"})\n",
    "#         for i in job_can_div:\n",
    "#             print(i.get_text())\n",
    "#     except:\n",
    "#         job_can_div=\" nono\"\n",
    "#         print(job_can_div)\n",
    "#     print(\"(其他條件)===================================\")\n",
    "#     try:\n",
    "#         c=div_results.index(\"其他條件\")\n",
    "#         job_other_div = new.find_all(\"div\",{\"class\":\"job_explain\"})[c+1].find_all(\"span\",{\"class\":\"exception\"})\n",
    "#         for i in job_other_div:\n",
    "#             print(i.get_text())\n",
    "#     except:\n",
    "#         job_other_div=\"nono \"\n",
    "#         print(job_other_div)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1387056-d53c-474a-ac0a-1c3e322329dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_results=[]\n",
    "for test2 in page_source_results:    \n",
    "    test3 = test2.find_all(\"div\",{\"class\":\"job_explain\"})[1:-1]\n",
    "    for i in test3 :        \n",
    "        test4 = i.find(\"h3\").text\n",
    "    div_results.append(test4)\n",
    "print(div_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd6f8c-6a00-4b59-8d09-eac0304e32cf",
   "metadata": {},
   "source": [
    "# 測試一頁搜尋結果(成功)\n",
    "\n",
    "前三個職缺所需的所有內容匯出成csv\n",
    "\n",
    "進度: 有兩個list\n",
    "    1. 搜尋結果頁能取出的\n",
    "    2. 詳細資料能取出的\n",
    "\n",
    "問題: 如何合併成一個完整list 匯出csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b0db0-1a6a-4981-9914-8d92a337676d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "s = Service(\"./chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "driver.get(\"https://www.yes123.com.tw/wk_index/joblist.asp?search_job_t=1&strrec=0&search_key_word=%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB&search_type=job&search_item=1&search_from=index\")\n",
    "time.sleep(2)\n",
    "job_titlepage = driver.page_source\n",
    "soup = BeautifulSoup(str(job_titlepage), 'html.parser')\n",
    "\n",
    "results2=[]\n",
    "# 所有公司的名稱和職缺\n",
    "job_titlepage_div = soup.find_all(\"div\",{\"class\":\"Job_opening_item\"})\n",
    "for title_bus in job_titlepage_div:\n",
    "# 職缺\n",
    "    all_titles = title_bus.find(\"h5\").get_text()\n",
    "    print(all_titles)\n",
    "# 公司名稱\n",
    "    all_bus= title_bus.find(\"h6\").get_text()\n",
    "    print(all_bus)\n",
    "#公司地址\n",
    "    all_addr=title_bus.find(\"div\",{\"class\":\"Job_opening_item_info\"}).find(\"span\").text\n",
    "    print(all_addr)\n",
    "    result2 ={\n",
    "             '職缺': all_titles,\n",
    "            '公司名稱': all_bus,\n",
    "            '公司地址':  all_addr\n",
    "        }\n",
    "    results2.append(result2)\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392f084-48dd-4235-9d65-9bf8c801b8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results=[]\n",
    "for new in page_source_results:\n",
    "    div_results=[]\n",
    "    test2 = new.find_all(\"div\",{\"class\":\"job_explain\"})[1:-1]\n",
    "    for okok in test2:\n",
    "        ok = okok.find(\"h3\").text\n",
    "        # print(ok)\n",
    "        div_results.append(ok)\n",
    "    #     div_results.append(okok)\n",
    "    # print(div_results)\n",
    "    # print(div_results.index(\"工作條件\"))\n",
    "    print(\"(學歷,科系要求)=============================================================\")\n",
    "    try:\n",
    "        a=div_results.index(\"工作條件\")\n",
    "        # print(a)\n",
    "        test4 =  new.find_all(\"div\",{\"class\":\"job_explain\"})[a+1].find_all(\"span\",{\"class\":\"right_main\"})[0].text\n",
    "        test3 = new.find_all(\"div\",{\"class\":\"job_explain\"})[a+1].find_all(\"span\",{\"class\":\"right_main\"})[1].text\n",
    "        print(test4)\n",
    "        print(test3)      \n",
    "    except:\n",
    "        test3=\" \"\n",
    "        print(test4)\n",
    "        print(test3)\n",
    "    print(\"(薪資)=============================================================\")\n",
    "    job_salary_div = new.find(\"div\",{\"class\":\"job_explain mt\"}).find_all(\"span\",{\"class\":\"right_main\"})[1].text\n",
    "    print(job_salary_div)\n",
    "    print(\"(工作內容)=============================================================\")\n",
    "    job_content_div = new.find(\"div\",{\"class\":\"job_explain mt\"}).find_all(\"span\",{\"class\":\"right_main\"})[0].text\n",
    "    print(job_content_div)\n",
    "    print(\"(擅長)=============================================================\")\n",
    "    try:\n",
    "        b=div_results.index(\"技能與求職專長\")\n",
    "        job_can_div = new.find_all(\"div\",{\"class\":\"job_explain\"})[b+1].find_all(\"span\",{\"class\":\"right_main\"})\n",
    "        for i1 in job_can_div:\n",
    "            job_can_text =i1.text  \n",
    "            print(job_can_text)\n",
    "    except:\n",
    "        job_can_text=\" \"\n",
    "        print(job_can_text)\n",
    "    print(\"(其他條件)===================================\")\n",
    "    try:\n",
    "        c=div_results.index(\"其他條件\")\n",
    "        job_other_div = new.find_all(\"div\",{\"class\":\"job_explain\"})[c+1].find_all(\"span\",{\"class\":\"exception\"})\n",
    "        for i2 in job_other_div:\n",
    "            job_other_text=i2.text\n",
    "            print(job_other_text)\n",
    "    except:\n",
    "        job_other_text=\" \"\n",
    "        print(job_other_text)\n",
    "    result ={\n",
    "             '學歷': test4,\n",
    "            '科系': test3,\n",
    "            '薪資':  job_salary_div,\n",
    "            '工作內容':job_content_div,\n",
    "            '擅長工具':job_can_text,\n",
    "            '其他條件':job_other_text\n",
    "        }\n",
    "    results.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1621ea87-8133-4d2e-9b32-2a8a492462e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 兩個list 各自有dict 做合併,這裡把results合併到results2\n",
    "for i in range(min(len(results2),len(results))):\n",
    "    results2[i].update(results[i])\n",
    "print(results2)\n",
    "\n",
    "labels =  ['職缺','公司名稱','公司地址','學歷','科系','薪資','工作內容','擅長工具','其他條件']\n",
    "dct_arr = results2\n",
    "try:\n",
    "    with open('onepage_work.csv', 'w',encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=labels)\n",
    "        writer.writeheader()\n",
    "        for elem in dct_arr:\n",
    "            writer.writerow(elem)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
