{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85e92995-74f1-469e-927e-2856ca5a86c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.yes123.com.tw/wk_index/joblist.asp?search_job_t=1&strrec=0&search_key_word=%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB&search_type=job&search_from=joblist', 'https://www.yes123.com.tw/wk_index/joblist.asp?search_job_t=1&strrec=30&search_key_word=%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB&search_type=job&search_from=joblist']\n"
     ]
    }
   ],
   "source": [
    "# 觀察搜尋結果網址,用網址切換頁數\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import ActionChains\n",
    "import csv\n",
    "s = Service(\"./chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "driver.get(\"https://www.yes123.com.tw/wk_index/joblist.asp?find_key2=%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB&order_ascend=desc&strrec=0&search_key_word=%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB&search_type=job&search_from=joblist\")\n",
    "allkey = driver.page_source\n",
    "time.sleep(2) \n",
    "soup = BeautifulSoup(str(allkey), 'html.parser')\n",
    "page=soup.find(\"div\",{\"id\":\"select_page_num\"}).find_all(\"option\")[:1]\n",
    "yes123_host = \"https://www.yes123.com.tw/wk_index/\"\n",
    "#取出所有頁數的數值\n",
    "pages=[]\n",
    "for i in page:    \n",
    "    allpage_value=int(i.text)\n",
    "    pages.append(allpage_value)\n",
    "pages.insert(0,0)\n",
    "#取出詳細內容的網址\n",
    "search_links=[]\n",
    "for search_pagevalue in pages :\n",
    "    search_link_part=\"joblist.asp?search_job_t=1&strrec=\"\n",
    "    search_link_part2= \"&search_key_word=%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB&search_type=job&search_from=joblist\"\n",
    "    search_link = yes123_host+search_link_part+str(search_pagevalue*30)+search_link_part2\n",
    "    search_links.append(search_link)\n",
    "search_pagesources=[]\n",
    "# 取出詳細頁面的內容\n",
    "for search_pagesource in search_links:\n",
    "    driver.get(search_pagesource)\n",
    "    time.sleep(2)\n",
    "    page_source = driver.page_source\n",
    "    page_source_soup = BeautifulSoup(str(page_source), 'html.parser')\n",
    "    search_pagesources.append(page_source_soup)\n",
    "link_results=[]\n",
    "results2=[]\n",
    "# 取出職缺,估僧名稱,公司地址\n",
    "\n",
    "for search_pagesource in  search_pagesources :   \n",
    "        job_titlepage_div = search_pagesource.find_all(\"div\",{\"class\":\"Job_opening_item\"})\n",
    "        for link in job_titlepage_div:\n",
    "            try:\n",
    "                all_part_links =link.find(\"h5\").find(\"a\").get(\"href\")\n",
    "                all_title_links = yes123_host+all_part_links  \n",
    "                link_results.append(all_title_links)\n",
    "                all_titles = link.find(\"h5\").get_text()\n",
    "                all_bus= link.find(\"h6\").get_text()\n",
    "                all_addr=link.find(\"div\",{\"class\":\"Job_opening_item_info\"}).find(\"span\").text\n",
    "                result2 ={\n",
    "                         '職缺': all_titles,\n",
    "                        '公司名稱': all_bus,\n",
    "                        '公司地址': all_addr\n",
    "                    }\n",
    "                results2.append(result2)\n",
    "            except:\n",
    "                continue\n",
    "detail_pagesource_results=[] \n",
    "#取出page_source\n",
    "for all_detail_page in link_results:\n",
    "\n",
    "    driver.get(all_detail_page)\n",
    "    time.sleep(2)\n",
    "    onepage_detail_pagesource = driver.page_source\n",
    "    time.sleep(1) \n",
    "    soup2 = BeautifulSoup(str(onepage_detail_pagesource), 'html.parser')   \n",
    "    detail_pagesource_results.append(soup2)     \n",
    "driver.close()\n",
    "all_h3_list =[]\n",
    "detail_results=[]\n",
    "#取出對應的資料內容\n",
    "for new in detail_pagesource_results:         \n",
    "    test2 = new.find_all(\"div\",{\"class\":\"job_explain\"})[1:] \n",
    "    h3_results=[]\n",
    "    for okok in test2:\n",
    "        h3_result=str(okok.find(\"h3\"))   \n",
    "        h3_results.append(h3_result)   \n",
    "    try:\n",
    "        a=h3_results.index(\"<h3>工作條件</h3>\")\n",
    "        # print(a)\n",
    "        test4 = new.find_all(\"div\",{\"class\":\"job_explain\"})[a+1].find_all(\"span\",{\"class\":\"right_main\"})[0].text\n",
    "        test3 = new.find_all(\"div\",{\"class\":\"job_explain\"})[a+1].find_all(\"span\",{\"class\":\"right_main\"})[1].text        \n",
    "    except:\n",
    "        test3=\" \"\n",
    "        test4=\" \"\n",
    "    job_salary_div = new.find(\"div\",{\"class\":\"job_explain mt\"}).find_all(\"span\",{\"class\":\"right_main\"})[1].text  \n",
    "    job_content_div = new.find(\"div\",{\"class\":\"job_explain mt\"}).find_all(\"span\",{\"class\":\"right_main\"})[0].text  \n",
    "    try:\n",
    "        b=h3_results.index(\"<h3>技能與求職專長</h3>\")\n",
    "        job_can_div = new.find_all(\"div\",{\"class\":\"job_explain\"})[b+1].find_all(\"span\",{\"class\":\"right_main\"})\n",
    "        for i1 in job_can_div:\n",
    "            job_can_text =i1.text          \n",
    "    except:\n",
    "        job_can_text=\" \"   \n",
    "    try:\n",
    "        c=h3_results.index(\"<h3>其他條件</h3>\")\n",
    "        job_other_div = new.find_all(\"div\",{\"class\":\"job_explain\"})[c+1].find_all(\"span\",{\"class\":\"exception\"})\n",
    "        for i2 in job_other_div:\n",
    "            job_other_text=i2.text           \n",
    "    except:\n",
    "        job_other_text=\" \"      \n",
    "    detail_result ={\n",
    "             '學歷': test4,\n",
    "            '科系': test3,\n",
    "            '薪資':  job_salary_div,\n",
    "            '工作內容':job_content_div,\n",
    "            '擅長工具':job_can_text,\n",
    "            '其他條件':job_other_text\n",
    "        }\n",
    "    detail_results.append(detail_result)\n",
    "#所有所需資訊合併成桐一個list\n",
    "for i in range(min(len(detail_results),len(results2))):\n",
    "    detail_results[i].update(results2[i])   \n",
    "# 輸出成csv\n",
    "labels =  ['職缺','公司名稱','公司地址','學歷','科系','薪資','工作內容','擅長工具','其他條件']\n",
    "dct_arr = detail_results\n",
    "try:\n",
    "    with open('03page_all_column.csv', 'w',encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=labels)\n",
    "        writer.writeheader()\n",
    "        for elem in dct_arr:\n",
    "            writer.writerow(elem)\n",
    "except IOError:\n",
    "     print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439ab87-8112-473a-b144-4adbd38ea5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
